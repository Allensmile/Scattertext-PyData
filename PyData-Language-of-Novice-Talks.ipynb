{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scattertext to Analyze PyData Talks\n",
    "Let's pull titles abstracts and descriptions of PyData talks to see how novice-level talks differed from intermediate and advanced talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re, time\n",
    "import pygal\n",
    "import scattertext as st\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "import seaborn as sns\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "import spacy\n",
    "import scattertext as st\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's scrape pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_talk(url):\n",
    "    d = {}\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "        content = soup.find_all('div', class_='container')[1]\n",
    "        d['author'] = content.find_all('a')[0].contents[0]\n",
    "        d['title'] = content.find_all('h2')[0].contents[0]\n",
    "        d['level'] = content.find_all('dd')[0].contents[0] \n",
    "        d['description'] = soup.find_all('div', class_='description')[0].get_text()\n",
    "        d['abstract'] = soup.find_all('div', class_='abstract')[0].get_text()\n",
    "    except:\n",
    "        print('bad', url)\n",
    "        return None\n",
    "    \n",
    "    return d\n",
    "\n",
    "def pull_pydata_schedule(loc, year):\n",
    "    url = 'https://pydata.org/'+loc+str(year)+'/schedule/'    \n",
    "    soup = BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "    content = soup.find_all('div', class_='container')[1]\n",
    "    talks = []\n",
    "    for slot in content.find_all('td', class_='slot'):\n",
    "        for link in slot.find_all('a'):   \n",
    "            d = parse_talk('https://pydata.org'+link.attrs['href'])\n",
    "            if d is not None:\n",
    "                d['location'] = loc\n",
    "                d['year'] = str(year)\n",
    "                talks.append(d)\n",
    "    time.sleep(5) # for politeness\n",
    "    print(loc, year)\n",
    "    return pd.DataFrame(talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seattle 2017\n",
      "london 2017\n",
      "bad https://pydata.orghttps://pydata.org/barcelona2017/schedule/presentation/42/\n",
      "bad https://pydata.orghttps://pydata.org/barcelona2017/schedule/presentation/33/\n",
      "bad https://pydata.orghttps://pydata.org/barcelona2017/schedule/presentation/34/\n",
      "bad https://pydata.orghttps://pydata.org/barcelona2017/schedule/presentation/52/\n",
      "barcelona 2017\n",
      "bad https://pydata.org/berlin2017/program/breakfast-and-lunch-program/\n",
      "bad https://pydata.org/berlin2017/keynote-speakers/\n",
      "bad https://pydata.org/berlin2017/program/breakfast-and-lunch-program/\n",
      "bad https://pydata.org/berlin2017/keynote-speakers#veronica-valeros\n",
      "bad https://pydata.org/berlin2017/program/breakfast-and-lunch-program/\n",
      "bad https://pydata.org/berlin2017/keynote-speakers#toby-walsh\n",
      "bad https://pydata.org/berlin2017/program/breakfast-and-lunch-program/\n",
      "bad https://pydata.org/berlin2017/keynote-speakers/#ethical-machine-learning-panel\n",
      "berlin 2017\n",
      "dc 2016\n",
      "carolinas 2016\n",
      "chicago 2016\n",
      "sfo 2016\n",
      "paris 2016\n",
      "berlin 2016\n",
      "london 2016\n"
     ]
    }
   ],
   "source": [
    "sched = pd.concat([pull_pydata_schedule('seattle', 2017),\n",
    "                   pull_pydata_schedule('london', 2017),\n",
    "                   pull_pydata_schedule('barcelona', 2017),                   \n",
    "                   pull_pydata_schedule('berlin', 2017),        \n",
    "                   pull_pydata_schedule('dc', 2016),\n",
    "                   pull_pydata_schedule('carolinas', 2016),\n",
    "                   pull_pydata_schedule('chicago', 2016),                   \n",
    "                   pull_pydata_schedule('sfo', 2016),                       \n",
    "                   pull_pydata_schedule('paris', 2016),                                                         \n",
    "                   pull_pydata_schedule('berlin', 2016),                   \n",
    "                   pull_pydata_schedule('london', 2016)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = sched[~sched['title'].isin(['BoF', 'Unconference Presentation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched['is_novice'] = (sched.level == 'Novice').apply(lambda x: 'Novice' if x else 'Not Novice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched['parse'] = (sched['title'] + '\\n \\n' + sched['abstract'] + '\\n \\n' + sched['description']).apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(sched, category_col = 'is_novice', parsed_col = 'parse').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_corpus = corpus.get_unigram_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/PydataNoviceVsNotNovice.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a986b278>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(unigram_corpus,\n",
    "                                       category='Novice',\n",
    "                                       category_name='Novice',\n",
    "                                       not_category_name='Not Novice',\n",
    "                                       minimum_term_frequency=3,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       term_ranker=st.OncePerDocFrequencyRanker,\n",
    "                                       use_full_doc=True,\n",
    "                                       metadata=sched['author'] + ' ('+sched['location'] + ', '+ sched['level'] + ')',)\n",
    "file_name = 'output/PydataNoviceVsNotNovice.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how the experiened talk descriptions sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/PydataAdvancedVsRest.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ab36e940>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sched['is_advanced'] = (sched.level == 'Experienced').apply(lambda x: 'Experienced' if x else 'Not Experienced')\n",
    "html = st.produce_scattertext_explorer(st.CorpusFromParsedDocuments(sched, category_col = 'is_advanced', parsed_col = 'parse').build(),\n",
    "                                       category='Experienced',\n",
    "                                       category_name='Experienced',\n",
    "                                       not_category_name='Not Experienced',\n",
    "                                       minimum_term_frequency=3,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       term_ranker=st.OncePerDocFrequencyRanker,\n",
    "                                       use_full_doc=True,\n",
    "                                       metadata=sched['author'] + ' ('+sched['location'] + ', '+ sched['level'] + ')',)\n",
    "file_name = 'output/PydataAdvancedVsRest.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
